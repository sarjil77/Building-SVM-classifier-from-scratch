{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmAaSt+kL15CyfJD0xqLyU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarjil77/Building-SVM-classifier-from-scratch/blob/main/Building_support_vector_classifer_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the dependencies"
      ],
      "metadata": {
        "id": "D6MChqWQQ8c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the numpy library\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "mcYWtDDlRBiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support vector machine classifier"
      ],
      "metadata": {
        "id": "Hn0RffyxRIKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we will formula for hyperplane as  = wx - b explanation is given in book."
      ],
      "metadata": {
        "id": "5CQ8-A81wKbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SVM_classifier():\n",
        "\n",
        "  # used for initiating the hyperparameters\n",
        "  def __init__(self,learning_rate, no_of_iterations, lambda_parameters):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.no_of_iterations = no_of_iterations\n",
        "    self.lambda_parameters = lambda_parameters\n",
        "\n",
        "  # fiting the datset to SVM classifier\n",
        "  def fit(self, X, Y):\n",
        "\n",
        "    # m is the number of rows and n is number of columns\n",
        "    self.m, self.n = X.shape\n",
        "\n",
        "    # initiating the weight and bias value\n",
        "    self.w = np.zeros(self.n)\n",
        "\n",
        "    self.b = 0\n",
        "\n",
        "    self.X = X\n",
        "\n",
        "    self.Y = Y\n",
        "\n",
        "    # implementing gredient descent algorithm for optimization\n",
        "\n",
        "    for i in range(self.no_of_iterations):\n",
        "      self.update_weights()\n",
        "\n",
        "\n",
        "  #function for updating the weights and bias value\n",
        "  def update_weights(self,):\n",
        "\n",
        "    # label encoding\n",
        "    y_label = np.where(self.Y <=0, -1, 1)\n",
        "\n",
        "\n",
        "    # gradients\n",
        "    # enumerate help us in giving the index to\n",
        "    # our every individual x_i so we can use that further\n",
        "\n",
        "    for index, x_i in enumerate(self.X):\n",
        "\n",
        "      # here it is the condition for using of formula of gredient descent\n",
        "      condition = y_label[index] * (np.dot(x_i, self.w) - self.b) >= 1\n",
        "\n",
        "      if (condition == True):\n",
        "\n",
        "        dw = 2 * self.lambda_parameters * self.w\n",
        "        db = 0\n",
        "\n",
        "      else:\n",
        "\n",
        "        dw = 2 * self.lambda_parameters * self.w - np.dot(x_i, y_label[index])\n",
        "        db = y_label[index]\n",
        "\n",
        "    # new weight and bias value\n",
        "      self.w = self.w - self.learning_rate * dw\n",
        "\n",
        "      self.b = self.b - self.learning_rate * db\n",
        "\n",
        "\n",
        "  # predict the label for given input value\n",
        "  def predict(self, X):\n",
        "\n",
        "    # equation of hyperplane(wx- b) here we are using eq as this.\n",
        "\n",
        "    output = np.dot(X, self.w) - self.b\n",
        "\n",
        "    predicted_labels = np.sign(output)\n",
        "\n",
        "    # changing of label as we have changed it earlier in this code\n",
        "    # if we dont do this than we will not correctr prediction\n",
        "\n",
        "    y_hat = np.where(predicted_labels <= -1, 0, 1)\n",
        "\n",
        "\n",
        "    return y_hat\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kG0ZdzKfRFRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "Up4316XMItil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the diabetes dataset in pandas dataframe\n",
        "diabetes_dataset = pd.read_csv('/content/diabetes.csv')"
      ],
      "metadata": {
        "id": "bQ8a4917IwHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separating the data and label\n",
        "features = diabetes_dataset.drop(columns = 'Outcome', axis = 1)\n",
        "target = diabetes_dataset['Outcome']"
      ],
      "metadata": {
        "id": "bt_e2G8eI_er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(features)\n",
        "standardized_data = scaler.transform(features )\n",
        "features  = standardized_data"
      ],
      "metadata": {
        "id": "4mPtQkwyJDHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size = 0.2, random_state = 2)"
      ],
      "metadata": {
        "id": "uBHWFktwJLJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Till above everything was same as i did before"
      ],
      "metadata": {
        "id": "27dXZcpRJPQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "wEfhJHkYJWlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = SVM_classifier(learning_rate = 0.01 , no_of_iterations =2000, lambda_parameters=0.01 )"
      ],
      "metadata": {
        "id": "O3rFYbprJOgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the svm classifier with training data\n",
        "classifier.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "wXUieWCmJxZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "f37bgHjAKpTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy score"
      ],
      "metadata": {
        "id": "ieACYj_9Ks45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy on training data\n",
        "X_train_prediction = classifier.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)"
      ],
      "metadata": {
        "id": "Qn0TYxsdKD54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuarcy score on training data = ', training_data_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqppTVzgK-kR",
        "outputId": "b78ab532-c394-47b7-a3e9-25c4a8f3e3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuarcy score on training data =  0.7768729641693811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy on test data\n",
        "X_test_prediction = classifier.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)"
      ],
      "metadata": {
        "id": "ptqvRIWELmAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuarcy score on training data =', test_data_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFGzhCJMLxo_",
        "outputId": "5730597a-d7b1-42c5-d067-3d6a2d92ba4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuarcy score on training data = 0.7467532467532467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a predictive system"
      ],
      "metadata": {
        "id": "vZrfoYoVMPwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = (10,162,84,0,0,27.7,0.182,54)\n",
        "\n",
        "# changing the input data to numpy array\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "\n",
        "# reshape the array as we are predicting for one instance\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "\n",
        "# standardize the input data\n",
        "std_data = scaler.transform(input_data_reshaped)\n",
        "# print(std_data)\n",
        "\n",
        "# prediction\n",
        "prediction = classifier.predict(std_data)\n",
        "# print(prediction)\n",
        "\n",
        "if (prediction[0] == 0):\n",
        "  print('person is non diabetic')\n",
        "else:\n",
        "  print('person is diabetic')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui5DTOxVL5K3",
        "outputId": "2db6e8d1-d14a-4801-ee59-30210d14a2e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "person is diabetic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PNUDtVR7MVYD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}